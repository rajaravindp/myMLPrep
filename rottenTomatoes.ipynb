{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "# !pip install accelerate -U"
      ],
      "metadata": {
        "id": "_IPYbhigg7-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "1Idt4osjg09V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Movie Review Dataset"
      ],
      "metadata": {
        "id": "pmO11w1ph4JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_dataset('rotten_tomatoes')"
      ],
      "metadata": {
        "id": "5jXuTyjLg4vW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588a2b33-e83c-450e-f2ae-636bc84216ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6dYr8hahE3w",
        "outputId": "d9033f3b-d905-469f-ce8d-b7135e4d0531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8JiU7DViwz4",
        "outputId": "e01d2e6f-e33f-48a4-a749-adf2a6c97469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['train'].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5g6_yQGizBv",
        "outputId": "1849175c-3842-4ffe-dfb9-b94a506a19fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['neg', 'pos'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['train']['text'][40:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovnfRUE2hGfi",
        "outputId": "f9863657-fa66-4e36-cfb4-9586a292454f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['newton draws our attention like a magnet , and acts circles around her better known co-star , mark wahlberg .',\n",
              " \"the story loses its bite in a last-minute happy ending that's even less plausible than the rest of the picture . much of the way , though , this is a refreshingly novel ride .\",\n",
              " 'fuller would surely have called this gutsy and at times exhilarating movie a great yarn .',\n",
              " \"'compleja e intelectualmente retadora , el ladr√≥n de orqu√≠deas es uno de esos filmes que vale la pena ver precisamente por su originalidad . '\",\n",
              " 'the film makes a strong case for the importance of the musicians in creating the motown sound .',\n",
              " 'karmen moves like rhythm itself , her lips chanting to the beat , her long , braided hair doing little to wipe away the jeweled beads of sweat .',\n",
              " 'gosling provides an amazing performance that dwarfs everything else in the film .',\n",
              " \"a real movie , about real people , that gives us a rare glimpse into a culture most of us don't know .\",\n",
              " 'tender yet lacerating and darkly funny fable .',\n",
              " \"may be spoofing an easy target -- those old '50's giant creature features -- but . . . it acknowledges and celebrates their cheesiness as the reason why people get a kick out of watching them today .\"]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['train']['label'][40:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CzE_YqFhNiB",
        "outputId": "ebb5e00a-55b8-46d7-c20d-8f752e639137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize text"
      ],
      "metadata": {
        "id": "FhOVvfanjJ5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "myTokenizer = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(myTokenizer)"
      ],
      "metadata": {
        "id": "wNd_myqNiGDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(inp):\n",
        "  return tokenizer(inp['text'], padding='max_length', truncation=True)"
      ],
      "metadata": {
        "id": "M7HryLAGjO5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk_df = df.map(tokenize, batched=True)"
      ],
      "metadata": {
        "id": "IVCMkZftjrfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ0EYZFmkozz",
        "outputId": "3799b607-f62a-4a39-add5-d0fbc656854e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to Pytorch datasets\n"
      ],
      "metadata": {
        "id": "hI0wuSsrpPNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert datasets to PyTorch datasets\n",
        "train_dataset = tk_df['train']\n",
        "val_dataset = tk_df['validation']\n",
        "test_dataset = tk_df['test']"
      ],
      "metadata": {
        "id": "R4v94QW7pTxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwaC22iV3nd5",
        "outputId": "64a0b56c-b7c2-4b19-f355-7443709ff553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 8530\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init model for classification"
      ],
      "metadata": {
        "id": "QbIdQ3qKp7zI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "myModel = 'distilbert-base-uncased'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(myModel, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhgupKPVp_OD",
        "outputId": "a6ff8dce-b1a2-4bd4-e009-17b832b73664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Training Args"
      ],
      "metadata": {
        "id": "xtXKGDbrrVpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./rottenResults',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./rottenLogs',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWcH8VGcrXmb",
        "outputId": "6910b3c5-1edc-4ab9-ef3a-a5e25ca2b500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init Trainer"
      ],
      "metadata": {
        "id": "w9vgOanuswN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, AdamW\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# Define compute_metrics function\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='binary')\n",
        "    acc = accuracy_score(labels, pred)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Define Optimizer to use\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Instantiate Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    optimizers=(optimizer, None),\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UHeGauzrbhn",
        "outputId": "36ed1bd9-2bbe-41ff-d747-d6f94ff80f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train(); train_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7u8BsqIvttMU",
        "outputId": "0eb165e1-a3dd-47e7-f220-3443c80eb22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1602' max='1602' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1602/1602 11:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.473900</td>\n",
              "      <td>0.362875</td>\n",
              "      <td>0.839587</td>\n",
              "      <td>0.835419</td>\n",
              "      <td>0.857708</td>\n",
              "      <td>0.814259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.292700</td>\n",
              "      <td>0.417444</td>\n",
              "      <td>0.841463</td>\n",
              "      <td>0.847885</td>\n",
              "      <td>0.814879</td>\n",
              "      <td>0.883677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.138000</td>\n",
              "      <td>0.648914</td>\n",
              "      <td>0.837711</td>\n",
              "      <td>0.837253</td>\n",
              "      <td>0.839623</td>\n",
              "      <td>0.834897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1602, training_loss=0.2896607460898258, metrics={'train_runtime': 682.3795, 'train_samples_per_second': 37.501, 'train_steps_per_second': 2.348, 'total_flos': 3389840731607040.0, 'train_loss': 0.2896607460898258, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval model on Val dataset"
      ],
      "metadata": {
        "id": "Y3Kb8moSxfXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = trainer.evaluate()\n",
        "# print(eval_result)\n",
        "\n",
        "print(\"Eval Accuracy:\", eval_result['eval_accuracy'])\n",
        "print(\"Eval F1-score:\", eval_result['eval_f1'])\n",
        "print(\"Eval Precision:\", eval_result['eval_precision'])\n",
        "print(\"Eval Recall:\", eval_result['eval_recall'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "lKVPBJEjt57u",
        "outputId": "c8b52b63-c18d-4716-816a-aaaa69795ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='102' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Accuracy: 0.8395872420262664\n",
            "Eval F1-score: 0.8354186717998076\n",
            "Eval Precision: 0.857707509881423\n",
            "Eval Recall: 0.8142589118198874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval model on Test dataset"
      ],
      "metadata": {
        "id": "qkAjaEg12xpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(test_dataset)\n",
        "# print(trest_results)\n",
        "\n",
        "print(\"Test Accuracy:\", test_results['eval_accuracy'])\n",
        "print(\"Test F1-score:\", test_results['eval_f1'])\n",
        "print(\"Test Precision:\", test_results['eval_precision'])\n",
        "print(\"Test Recall:\", test_results['eval_recall'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "R6Jn7x14xgp2",
        "outputId": "ab0bd900-32c7-44c8-eb6f-4cbe1e045b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:19]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8367729831144465\n",
            "Test F1-score: 0.8326923076923077\n",
            "Test Precision: 0.854043392504931\n",
            "Test Recall: 0.8123827392120075\n"
          ]
        }
      ]
    }
  ]
}